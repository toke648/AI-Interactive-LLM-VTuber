# Interactive-LLM-VTuber

[![license](https://img.shields.io/github/license/toke648/Interactive-LLM)](https://github.com/toke648/Interactive-LLM/blob/main/LICENSE) 

## What is this project
This project is a simple VTuber backend model (the frontend is currently learning and configuring)
It can achieve simple voice input, voice output, LLM, and interactive effects.

## Demo（In development）
![image](https://github.com/user-attachments/assets/2b5378ce-fe18-44d4-8a1f-ddb76b5ffda6)


## Constructed by
<div>
  <p>python</p>
  <p>Speech Recognition (ASR): speech_recognition</p>
  <p>Large Language Model(LLM): Tongyi Qianwen</p>
  <p>text to speech (TTS): edge-tts</p>
</div>

## Mem0 (In development)


## Target Platform

- Windows
- Linux  <I didn't test it, but it should be possible

## How to work it
<p>Download Vscode or Pycharm</p>

pip install -r requirements.txt # Run this in the project directory 
